{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "894dca8a-6390-4eef-a4d7-e35e10a03019",
   "metadata": {},
   "source": [
    "# Hybrid Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf75429-2cd9-417f-8ba7-4f56b15a0a31",
   "metadata": {},
   "source": [
    "## Extrapolating Trends vs Interaction:\n",
    "\n",
    "1. Extrapolating Trends:\n",
    "   - Extrapolating trends involves extending existing patterns or trends into the future beyond the observed data points. This is typically done using mathematical models or statistical techniques to predict future values based on historical data.\n",
    "   - For example, if you have data on the sales of a product over the past few years, you can use extrapolation to predict future sales based on the observed trend in sales growth or decline.\n",
    "   - It's important to note that extrapolating trends assumes that past patterns will continue into the future, which may not always be accurate, especially if there are unforeseen changes or disruptions in the underlying factors driving the trend.\n",
    "3. Iteraction Trends:\n",
    "   - Interaction trends refer to patterns or relationships between different factors that influence each other's behavior or trends over time.\n",
    "   - In data analysis, interaction effects are often examined in statistical models to understand how the relationship between two or more variables changes based on the levels of other variables.\n",
    "   - For example, in a study on the effect of a new drug on patients' health outcomes, interaction effects might be explored to see if the effectiveness of the drug varies depending on factors like age, gender, or the presence of other health conditions.\n",
    "   - Identifying interaction trends can provide deeper insights into how various factors interact and influence outcomes, helping to refine predictions or decision-making processes.\n",
    "\n",
    "> Summary:\n",
    "> - extrapolating trends involves projecting existing patterns into the future;\n",
    "> - interaction trends involve understanding how different variables interact and influence each other's trends or behaviors over time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c62517a-a0f8-47b4-892b-63d8050edaaf",
   "metadata": {},
   "source": [
    "**Linear regression** excels at extrapolating trends, but can't learn interactions. \n",
    "**XGBoost** excels at learning interactions, but can't extrapolate trends. \n",
    "\n",
    "In this lesson, we'll learn how to create \"hybrid\" forecasters that combine complementary learning algorithms and let the strengths of one make up for the weakness of the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d38880-1f69-498a-bc5b-746f6263e000",
   "metadata": {},
   "source": [
    "## Components and Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d05ed-c1a6-452d-a7d8-19543066f514",
   "metadata": {},
   "source": [
    "We've studied three patterns of time series dependences: \n",
    "1. trend\n",
    "2. seasons \n",
    "3. cycles\n",
    "\n",
    "A time series can be closely described by these components plus some unpredictable and random error:\n",
    "\n",
    "**`series = trend + seasons + cycles + error`**\n",
    "    \n",
    "Each of the terms in this model we would then call a **component** of the time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d04e5d-ab70-4d13-9ac2-899696327aeb",
   "metadata": {},
   "source": [
    "**Residuals** are:\n",
    "* the difference between the `target` on training and the `predictions` the model makes, or \n",
    "* the difference between the actual curve and the fitted curve\n",
    "\n",
    "Plot the `residuals` against a feature, you get:\n",
    "* the `\"left over\"` part of the target, or\n",
    "* what the model failed to learn about the target from that feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec983d1-8a14-43d9-840f-9a395d300cdb",
   "metadata": {},
   "source": [
    "### Residuals vs Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b9831a-58eb-4616-84c2-e9ebc3f4e8ad",
   "metadata": {},
   "source": [
    "* **Residuals**: \n",
    "  Residuals refer to the differences between the observed values and the values predicted by the time series model. They represent the unexplained variability in the data after the model has been fit. In other words, residuals are the discrepancies between the actual data points and the values predicted by the model.\n",
    "* **Errors**: \n",
    "  Errors, on the other hand, represent the difference between the observed values and the true values of the phenomenon being modeled. In time series analysis, the true values are often unknown or not directly observable, so errors are theoretical constructs. Errors include any factors that contribute to the discrepancy between the observed data and the true underlying process, such as measurement error or unmodeled variability.\n",
    "\n",
    "Residuals and errors are related but not identical. Residuals are observable quantities derived from the model fitting process, whereas errors are theoretical constructs representing the difference between observed and true values. In practice, however, the terms \"residuals\" and \"errors\" are sometimes used interchangeably, especially when discussing model diagnostics or forecasting accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044f3e9d-7a56-4a99-aac7-f51ed3fb806f",
   "metadata": {},
   "source": [
    "## Hybrid Forecasting with Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447a5c7d-8560-4cfa-9050-73529de97edf",
   "metadata": {},
   "source": [
    "Hybird multiple models example: use one algorithm to fit the original series; then the second algorithm to fit the residual series.\n",
    "\n",
    "```python\n",
    "# 1. Train and predict with first model\n",
    "model_1.fit(X_train_1, y_train)\n",
    "y_pred_1 = model_1.predict(X_train)\n",
    "\n",
    "# 2. Train and predict with second model on residuals\n",
    "model_2.fit(X_train_2, y_train - y_pred_1)\n",
    "y_pred_2 = model_2.predict(X_train_2)\n",
    "\n",
    "# 3. Add to get overall predictions\n",
    "y_pred = y_pred_1 + y_pred_2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24091d9c-6368-4fa3-8a2a-f5df1b957173",
   "metadata": {},
   "source": [
    "Usually features of each model are various (X_train_1 and X_train_2 above). If first model learns trend, the second model generally wouldn't need a trend feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe06c090-633f-44de-8b54-dfa3734d69cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
